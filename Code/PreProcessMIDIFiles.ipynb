{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596f391e",
   "metadata": {},
   "source": [
    "# Automated Music Composition Usings GANs \n",
    "## Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c10212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, key, note, chord, pitch, meter, tempo, interval\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imageio import imwrite, imread\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71812492",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = ['S','A','T','B']\n",
    "\n",
    "# Dictionary to convert between MIDI Numbers and Notes\n",
    "midiNumberNote = {n:str(pitch.Pitch(n)) for n in range(1,128)}\n",
    "midiNoteNumber = {v:k for k,v in midiNumberNote.items()}\n",
    "\n",
    "def save_image(img, out_fn, out_path):\n",
    "    Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    imwrite(os.path.join(out_path,out_fn), img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c55a6",
   "metadata": {},
   "source": [
    "## Preparing MIDI Files\n",
    "### Transpose to C Major/A Minor and Convert Instruments to Piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48659774",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallels = ['CMCm','C#MC#m','DMDm','D#MD#m','EMEm','FMFm','F#MF#m','GMGm','G#MG#m','AMAm','A#MA#m','BMBm']\n",
    "relatives = ['CMAm','C#MA#m','DMBm','D#MCm','EMC#m','FMDm','F#MD#m','GMEm','G#MFm','AMF#m','A#MGm','BMG#m']\n",
    "\n",
    "def transpose_midi(key_tp,mode):\n",
    "    \n",
    "    midi_path = '../Data/MidiFiles/'\n",
    "    in_dir = os.path.join(midi_path,'JSB-Midi')\n",
    "    out_dir = os.path.join(midi_path,'JSB-Midi-TP/{}/JSB-Midi-TP-{}'.format(mode,key_tp))\n",
    "    if not os.path.exists(out_dir): os.makedirs(out_dir)\n",
    "    if not os.path.exists(out_dir): os.makedirs(out_dir)\n",
    "        \n",
    "    major_key = key_tp[:2]    if '#' in key_tp[:2]  else key_tp[0]\n",
    "    minor_key = key_tp[-3:-1] if '#' in key_tp[-2:] else key_tp[-2]\n",
    "    tp_keys = {'major':major_key,'minor':minor_key}\n",
    "    \n",
    "    print('Transposing to {} Major and {} Minor'.format(major_key,minor_key))\n",
    "    \n",
    "    # Loop thorugh all MIDI files\n",
    "    for file in os.listdir(in_dir):\n",
    "        # Read MIDI file with music21\n",
    "        score = converter.parse(os.path.join(in_dir,file))\n",
    "        \n",
    "        # Extract the key signature of the music and find the transposition interval\n",
    "        key = score.analyze('key')\n",
    "        i = interval.Interval(key.tonic, pitch.Pitch(tp_keys[key.mode]))\n",
    "        \n",
    "        # Write the transposed MIDI file, and validate correct transposition\n",
    "        newscore = score.transpose(i)\n",
    "        newkey = newscore.analyze('key')\n",
    "        \n",
    "        # Save the transposed MIDI file\n",
    "        newscore.write('midi',os.path.join(out_dir,'tp_'+file))\n",
    "        \n",
    "    return midi_path\n",
    "                \n",
    "for k in parallels:\n",
    "    midi_path = transpose_midi(k,'Parallel')\n",
    "for k in relatives:\n",
    "    midi_path = transpose_midi(k,'Relative')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ce207",
   "metadata": {},
   "source": [
    "## Converting MIDI Files to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078042fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def midi2array(tp, mode):\n",
    "    \n",
    "    \n",
    "    notes_df = pd.DataFrame(index=os.listdir(os.path.join(midi_path,'JSB-Midi')),columns=voices)\n",
    "    notes_letter_df = pd.DataFrame(index=os.listdir(os.path.join(midi_path,'JSB-Midi')),columns=voices)\n",
    "    durations_df = pd.DataFrame(index=os.listdir(os.path.join(midi_path,'JSB-Midi')),columns=voices)\n",
    "    start_df = pd.DataFrame(index=os.listdir(os.path.join(midi_path,'JSB-Midi')),columns=voices)\n",
    "\n",
    "    notes_dict, notes_letter_dict, durations_dict, start_dict = {},{},{},{}\n",
    "\n",
    "    inpath = \"JSB-Midi\" if tp == \"notTP\" else os.path.join(midi_path,\"JSB-Midi-TP\",mode,f\"JSB-Midi-TP-{tp}\")\n",
    "    outpath = os.path.join(os.path.join('../Data','ProcessedData',mode,tp)\n",
    "    if tp not in os.listdir(f'ProcessedData/{mode}'): os.makedirs(outpath) \n",
    "\n",
    "    full_dict = defaultdict(dict)\n",
    "\n",
    "    for file in os.listdir(\"JSB-Midi\"):\n",
    "\n",
    "        if tp != \"notTP\": file = f\"tp_{file}\"\n",
    "        fn = os.path.join(inpath,file)\n",
    "        \n",
    "        original_score = converter.parse(fn)\n",
    "\n",
    "        for i,p in enumerate(voices):\n",
    "            notes, notes_letter, durations, start = [],[],[],[]\n",
    "\n",
    "            if len(original_score.parts) == 4:\n",
    "                for element in original_score.parts[i].flat:\n",
    "                    if isinstance(element, note.Note):\n",
    "                        notes.append(element.pitch.ps)\n",
    "                        if element.isRest: notes_letter.append(str(element.name))\n",
    "                        else:              notes_letter.append(str(element.nameWithOctave))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "                        start.append(element.offset)\n",
    "\n",
    "                durations_df.loc[file,p] = durations\n",
    "                notes_df.loc[file,p] = notes\n",
    "                notes_letter_df.loc[file,p] = notes_letter\n",
    "                start_df.loc[file,p] = start\n",
    "\n",
    "                full_dict[file][p] = {\"start\":start, \"pitch\":notes, \"dur\":durations, \"pitch_letter\":notes_letter}\n",
    "            \n",
    "            else: print(file)\n",
    "    with open(outpath+'/full_chorales_{}.json'.format(tp),'w') as fn:\n",
    "        json.dump(full_dict,fn)\n",
    "\n",
    "    durations_df.to_csv(outpath + '/JSB_durations_{}.csv'.format(tp))\n",
    "    notes_df.to_csv(outpath + '/JSB_notes_{}.csv'.format(tp))\n",
    "\n",
    "    start_df.to_csv(outpath + '/JSB_start_{}.csv'.format(tp))\n",
    "\n",
    "    with open(outpath+'/full_chorales_{}.json'.format(tp),'r') as fn:\n",
    "        read_full_dict = json.load(fn)\n",
    "\n",
    "    \n",
    "    return read_full_dict\n",
    "\n",
    "midi2array('notTP',mode='notTP')\n",
    "for k in relatives:\n",
    "    midi2array(k,mode='Relative')\n",
    "for k in parallels:\n",
    "    midi2array(k,mode='Parallel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f746400",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "96e4744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration(tp):\n",
    "    \n",
    "    outpath = \"ProcessedData/{}/\".format(tp)\n",
    "    \n",
    "    with open(outpath+'full_chorales_{}.json'.format(tp),'r') as fn:\n",
    "        read_full_dict = json.load(fn)\n",
    "    all_notes = []\n",
    "    all_notenums = []\n",
    "    lengths = []\n",
    "    \n",
    "    for n,d in read_full_dict.items():\n",
    "        lengths.append((d['S']['start'][-1]+d['S']['dur'][-1])/4)\n",
    "        for v,data in d.items():\n",
    "            [all_notes.append(note) for note in data['pitch_letter']]\n",
    "            [all_notenums.append(note) for note in data['pitch']]\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    print('Highest Pitch in Dataset:',pitch.Pitch(max(all_notenums)))\n",
    "    print('Lowest  Pitch in Dataset:',pitch.Pitch(min(all_notenums)))\n",
    "    plt.hist(all_notenums)\n",
    "    if tp=='CMAm':  plt.title('Pitch Distribution of Chorales Transposed to C Major and A Minor')\n",
    "    if tp=='CMCm':   plt.title('Pitch Distribution of Chorales Transposed to C Major and C Minor')\n",
    "    if tp=='notTP': plt.title('Pitch Distribution of Non-Transposed Chorales')\n",
    "    \n",
    "    unique_notes, unique_counts = np.unique(list(map(lambda x:x[:-1],all_notes)),return_counts=True)\n",
    "       \n",
    "    labels_histogram = dict(zip(unique_notes, unique_counts))\n",
    "            \n",
    "    note_order = ['C', 'C#', 'D', 'E-','E', 'F', 'F#', 'G', 'G#', 'A', 'B-', 'B' ]\n",
    "\n",
    "    sorted_notecount = {n:labels_histogram[n] for n in note_order}   \n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(sorted_notecount.keys(),sorted_notecount.values())\n",
    "    if tp=='CMAm':  plt.title('Note Distribution of Chorales Transposed to C Major and A Minor')\n",
    "    if tp=='CMCm':   plt.title('Note Distribution of Chorales Transposed to C Major and C Minor')\n",
    "    if tp=='notTP': plt.title('Note Distribution of Non-Transposed Chorales')\n",
    "  \n",
    "    plt.xlabel('Note')\n",
    "    plt.ylabel('Occurences in Transposed Dataset')\n",
    "#     plt.savefig('{}NoteDist.png'.format(tp))\n",
    "    \n",
    "    \n",
    "\n",
    "data_exploration('CMCm')\n",
    "data_exploration('CMAm')\n",
    "data_exploration('notTP')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f5466",
   "metadata": {},
   "source": [
    "## Piano Roll (Image) Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d9796",
   "metadata": {},
   "source": [
    "### Array to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad144d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def array2image(midi_path,image_width,monophonic,tp,mode,q,square=True,save=True):\n",
    "\n",
    "    # Load Arrays\n",
    "    with open(os.path.join('ProcessedData',mode,tp,'full_chorales_{}.json'.format(tp)),'r') as fn:\n",
    "        data = json.load(fn)[midi_path]\n",
    "    \n",
    "    min_pitch, max_pitch = 26, 90 # D1, F#6 in MIDI numbers\n",
    "    image_arr = np.zeros((max_pitch-min_pitch,image_width)) # Empty array to be filled where notes occur\n",
    "    out_dir = os.path.join('ProcessedData',mode,tp,'NewImages',str(image_width))\n",
    "\n",
    "    for voice, values in data.items():\n",
    "        for i,note in enumerate(values[\"pitch\"]): # Loop for all occuring pitches\n",
    "\n",
    "            # Normalising by q and converting start and duration of notes to int quantises them to chosen level\n",
    "            dur = int(values[\"dur\"][i]/q)\n",
    "            start = int(values[\"start\"][i]/q)\n",
    "\n",
    "            # For each pitch that occurs in the music, populate all occurences across the image\n",
    "            if dur+start < image_width:\n",
    "                for j in range(start,start+dur):\n",
    "                    if j >= 0:\n",
    "                        image_arr[(max_pitch-min_pitch)-int(note-min_pitch),j] = 255\n",
    "            else: break\n",
    "           \n",
    "        if save and monophonic:\n",
    "            # Saving Monophonic Images part-by-part (S, A, T, B)\n",
    "            out_fn = midi_path.replace(\".mid\",f\"_{voice}_{tp}.png\")\n",
    "            save_image(image_arr, out_fn, os.path.join(out_dir,'Monophonic',voice))\n",
    "            image_arr = np.zeros((max_pitch-min_pitch,image_width))\n",
    "    \n",
    "    if save and not monophonic:\n",
    "        # Saving Polyphonic Images with All Parts\n",
    "        out_fn = midi_path.replace(\".mid\",f\"_{tp}.png\")\n",
    "        save_image(image_arr, out_fn, os.path.join(out_dir,'Polyphonic'))\n",
    "\n",
    "with open(os.path.join('ProcessedData','Relative','CMAm','full_chorales_CMAm.json'),'r') as fn:\n",
    "    files = json.load(fn).keys()     \n",
    "\n",
    "q = 0.5             # Quantisation Level\n",
    "img_width = int(64) # Width of Image\n",
    "\n",
    "for file in files:\n",
    "    print(file,end=' ')\n",
    "    print('Relatives...',end=' ')\n",
    "    for k in relatives:\n",
    "        array2image(file,img_width,False,k,'Relative',q)\n",
    "        array2image(file,img_width,True,k,'Relative',q)\n",
    "    print('Parallels...')\n",
    "    for k in parallels:\n",
    "        array2image(file,img_width,False,k,'Parallel',q)\n",
    "        array2image(file,img_width,True,k,'Parallel',q)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede2325",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4e811d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(img_width,mode):\n",
    "    \n",
    "    '''\n",
    "    Combines all transpositions into one folder\n",
    "    '''\n",
    "\n",
    "    source = 'ProcessedData/Parallel'\n",
    "    dest = f'ProcessedData/12keysNew/{mode}'\n",
    "    Path(dest).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for k in os.listdir(source):\n",
    "        if not k.startswith('.'):\n",
    "            img_path = os.path.join(source,k,'NewImages',str(img_width),'Polyphonic')\n",
    "            for file in os.listdir(img_path):\n",
    "                shutil.copyfile(os.path.join(img_path,file),os.path.join(dest,file))\n",
    "\n",
    "data_augmentation(64,'Polyphonic')\n",
    "data_augmentation(64,'Monophonic/S')\n",
    "data_augmentation(64,'Monophonic/A')\n",
    "data_augmentation(64,'Monophonic/T')\n",
    "data_augmentation(64,'Monophonic/B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
